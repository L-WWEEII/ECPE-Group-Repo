{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "We use the following example for explaination.\n",
    "\n",
    "4 12\n",
    " (12,9), (12,10), (12,11)\n",
    "1,null,null,为 尽快 将 女子 救 下\n",
    "2,null,null,指挥员 立即 制订 了 救援 方案\n",
    "3,null,null,第一组 在 楼下 铺设 救生 气垫\n",
    "4,null,null,并 对 周围 无关 人员 进行 疏散\n",
    "5,null,null,另一组 队员 快速 爬 上 6 楼\n",
    "6,null,null,在 楼 内 对 女子 进行 劝说\n",
    "7,null,null,劝说 过程 中\n",
    "8,null,null,消防官兵 了解 到\n",
    "9,null,null,因为 该 女子 是 由于 对方 拖欠 工程款  # insert '因为'\n",
    "10,null,null,家中 又 急需 用钱\n",
    "11,null,null,生活 压力 大\n",
    "12,sadness,无奈,以致 无奈 才 选择 跳楼 轻生  # insert '以致'\n",
    "\n",
    "'''\n",
    "\n",
    "import csv\n",
    "\n",
    "# Define class\n",
    "class Statistics():\n",
    "    def __init__(self, key, emo_conn, cau_conn, type, dis):\n",
    "        self.key = key\n",
    "        self.emo_conn = emo_conn\n",
    "        self.cau_conn = cau_conn\n",
    "        self.type = type\n",
    "        self.dis = dis\n",
    "        self.frequency = 0\n",
    "\n",
    "# Init param\n",
    "result = []  # Statistic result\n",
    "key = []  # Primary key for index\n",
    "conn_words = []  # Set connectives\n",
    "\n",
    "# Load cause connectives\n",
    "with open ('cause_conn.txt', 'r', encoding='utf-8') as f:\n",
    "    line = f.readline()\n",
    "    while line:\n",
    "        for word in line.split(','):\n",
    "            conn_words.append(word)\n",
    "        line = f.readline()\n",
    "\n",
    "with open ('test.txt', 'r', encoding='utf-8') as f:  # Encode by utf-8 for Chinese\n",
    "    sec = f.readline()  # Read section ID and length\n",
    "\n",
    "    # For each section\n",
    "    while sec:\n",
    "\n",
    "        # Get section length\n",
    "        num = sec.split(' ')\n",
    "        length = int(num[1])\n",
    "        content = ['' for i in range(length)]\n",
    "        refined_content = ['' for i in range(length)]\n",
    "\n",
    "        pairs = f.readline().lstrip().rstrip()  # Get the index of pairs and delete the beginning ' ' and ending '\\n'\n",
    "\n",
    "        # Get the index of pairs (int)\n",
    "        pairs_index = []\n",
    "        for pair in pairs.split(', '):\n",
    "            pairs_index.append(list(map(int, pair.lstrip('(').rstrip(')').split(','))))\n",
    "\n",
    "        # Get the content of section\n",
    "        for i in range(length):\n",
    "            content[i] = f.readline().lstrip().rstrip().split(',')[3]\n",
    "\n",
    "            # Get the raw content\n",
    "            for word in content[i].split(' '):\n",
    "                refined_content[i] += word\n",
    "        \n",
    "        # For each pair\n",
    "        for pair in pairs_index:\n",
    "            dis = pair[1] - pair[0]  # Calculate dis = cause - emotion\n",
    "\n",
    "            # Emotion clause\n",
    "            emo_conn_flag = 0  # Set no conn as default\n",
    "            emo_conn = ''\n",
    "            # Judge double-character word later to cover the result as long as possible\n",
    "            for i in range(len(refined_content[pair[1] - 1])):  # Single-character word\n",
    "                if refined_content[pair[1] - 1][i] in conn_words:\n",
    "                    emo_conn_flag = 1\n",
    "                    emo_conn = refined_content[pair[1] - 1][i]\n",
    "            for i in range(len(refined_content[pair[1] - 1]) - 1):  # Double-character word\n",
    "                possible_conn = refined_content[pair[1] - 1][i] + refined_content[pair[1] - 1][i + 1]\n",
    "                if possible_conn in conn_words:\n",
    "                    emo_conn_flag = 1\n",
    "                    emo_conn = possible_conn\n",
    "            \n",
    "            # Cause clause\n",
    "            cau_conn_flag = 0  # Set no conn as default\n",
    "            cau_conn = ''\n",
    "            # Judge double-character word later to cover the result as long as possible\n",
    "            for i in range(len(refined_content[pair[0] - 1])):  # Single-character word\n",
    "                if refined_content[pair[0] - 1][i] in conn_words:\n",
    "                    cau_conn_flag = 1\n",
    "                    cau_conn = refined_content[pair[0] - 1][i]\n",
    "            for i in range(len(refined_content[pair[0] - 1]) - 1):  # Double-character word\n",
    "                possible_conn = refined_content[pair[0] - 1][i] + refined_content[pair[0] - 1][i + 1]\n",
    "                if possible_conn in conn_words:\n",
    "                    cau_conn_flag = 1\n",
    "                    cau_conn = possible_conn\n",
    "\n",
    "            # Judge structure type\n",
    "            # type0 (emo, cau), type1 (emo, conn, cau), type2 (conn, emo, cau), type3 (conn, emo, conn, cau)\n",
    "            # We always rewrite the sentence to make sure emo is ahead of cau for our research\n",
    "            type = 0\n",
    "            if cau_conn_flag == 1:\n",
    "                type = 1\n",
    "            if emo_conn_flag == 1:\n",
    "                type = 2\n",
    "            if cau_conn_flag == 1 & emo_conn_flag == 1:\n",
    "                type = 3\n",
    "\n",
    "            # Get statistics\n",
    "            pair_key = emo_conn + cau_conn + str(type) + str(dis)  # Set unique key\n",
    "\n",
    "            if pair_key not in key:\n",
    "                key.append(pair_key)\n",
    "                new_situation = Statistics(pair_key, emo_conn, cau_conn, type, dis)\n",
    "                result.append(new_situation)\n",
    "            \n",
    "            result[key.index(pair_key)].frequency += 1\n",
    "\n",
    "        sec = f.readline()  # Read following section length\n",
    "\n",
    "# Write result in csv\n",
    "with open ('test_result.csv', 'w', encoding='utf-8', newline='') as f:\n",
    "    csv_writer = csv.writer(f)\n",
    "\n",
    "    csv_writer.writerow(['pair_key', 'emo_conn', 'cau_conn', 'type', 'dis', 'frequency'])\n",
    "    for item in result:\n",
    "        csv_writer.writerow([item.key, item.emo_conn, item.cau_conn, item.type, item.dis, item.frequency])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4cff3abf1678755e0069fd79299a535fe1940bcd71a6b01d9f4386710b2b163f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
