{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all\n",
      "tensor([[-7.8889, -7.7087, -7.6812,  ..., -7.5645, -6.7353, -7.1856]],\n",
      "       device='cuda:7')\n",
      "tensor([[-0.0002, -0.0002, -0.0002,  ..., -0.0002, -0.0001, -0.0001]],\n",
      "       device='cuda:7')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "\n",
    "# Designate device\n",
    "device = torch.device(\"cuda:7\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Set model as bert-base-uncased and use BertForMaskedLM\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "text = \"[CLS] We want to thank some people [SEP] [MASK] those people helped me [SEP]\"\n",
    "tokenized_text = tokenizer.tokenize(text)\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "\n",
    "# Create the tensors of segments\n",
    "# ['[CLS]', 'we', 'want', 'to', 'thank', 'some', 'people', '[SEP]', '[MASK]', 'those', 'people', 'helped', 'me', '[SEP]']\n",
    "segments_ids = [0] * 8 + [1] * 6\n",
    "\n",
    "# Convert tensors to Pytorch tensors\n",
    "tokens_tensor = torch.tensor([indexed_tokens]).to(device)\n",
    "segments_tensors = torch.tensor([segments_ids]).to(device)\n",
    "\n",
    "# Set mode to evaluation\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "# Get MASK index\n",
    "def get_index1(lst=None, item=''):\n",
    "    return [index for (index,value) in enumerate(lst) if value == item]\n",
    "masked_index = get_index1(tokenized_text, '[MASK]')\n",
    "\n",
    "# Get prediction\n",
    "with torch.no_grad():\n",
    "    # [1，14，30522] # [#batch, #word, #vocab]\n",
    "    # Outputs are the probabilities of words\n",
    "    outputs = model(tokens_tensor, token_type_ids=segments_tensors)\n",
    "predictions = outputs[0]  # [1，14，30522] # [#batch, #word, #vocab]\n",
    "\n",
    "# Predict single word\n",
    "predicted_index = torch.argmax(predictions[0, masked_index]).item()\n",
    "\n",
    "# Transform index into word\n",
    "predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])[0]\n",
    "print(predicted_token)\n",
    "\n",
    "# Probability distribution\n",
    "print(torch.exp(predictions[0, masked_index])/torch.sum(torch.exp(predictions[0, masked_index])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mytransformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
