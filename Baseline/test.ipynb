{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from config import *\n",
    "import torch\n",
    "from data_loader import *\n",
    "from utils.utils import *\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup, BertTokenizer\n",
    "from rank_cp import Network\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class OriginalDataset(Dataset):\n",
    "    def __init__(self, pre_data):\n",
    "        self.docid_list = pre_data['_docid_list']\n",
    "        self.clause_list = pre_data['_clause_list']\n",
    "        self.doc_len_list = pre_data['_doc_len_list']\n",
    "        self.clause_len_list = pre_data['_clause_len_list']\n",
    "        self.pairs = pre_data['_pairs']\n",
    "\n",
    "        self._f_emo_query = pre_data['_f_emo_query']  # [1, max_for_emo_len]\n",
    "        self._f_cau_query = pre_data['_f_cau_query']  # [max_for_num, max_for_cau_len]\n",
    "        self._f_emo_query_len = pre_data['_f_emo_query_len']\n",
    "        self._f_cau_query_len = pre_data['_f_cau_query_len']\n",
    "        self._f_emo_query_answer = pre_data['_f_emo_query_answer']\n",
    "        self._f_cau_query_answer = pre_data['_f_cau_query_answer']\n",
    "        self._f_emo_query_mask = pre_data['_f_emo_query_mask']  # [1,max_for_emo_len]\n",
    "        self._f_cau_query_mask = pre_data['_f_cau_query_mask']  # [max_for_num, max_for_cau_len]\n",
    "        self._f_emo_query_seg = pre_data['_f_emo_query_seg']  # [1,max_for_emo_len]\n",
    "        self._f_cau_query_seg = pre_data['_f_cau_query_seg']  # [max_for_num, max_for_cau_len]\n",
    "\n",
    "        self._b_emo_query = pre_data['_b_emo_query']\n",
    "        self._b_cau_query = pre_data['_b_cau_query']  #\n",
    "        self._b_emo_query_len = pre_data['_b_emo_query_len']\n",
    "        self._b_cau_query_len = pre_data['_b_cau_query_len']\n",
    "        self._b_emo_query_answer = pre_data['_b_emo_query_answer']\n",
    "        self._b_cau_query_answer = pre_data['_b_cau_query_answer']\n",
    "        self._b_emo_query_mask = pre_data['_b_emo_query_mask']  #\n",
    "        self._b_cau_query_mask = pre_data['_b_cau_query_mask']  #\n",
    "        self._b_emo_query_seg = pre_data['_b_emo_query_seg']  #\n",
    "        self._b_cau_query_seg = pre_data['_b_cau_query_seg']  #\n",
    "\n",
    "        self._forward_c_num = pre_data['_forward_c_num']\n",
    "        self._backward_e_num = pre_data['_backward_e_num']\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_one_batch(configs, batch, model, tokenizer):\n",
    "    # 一个文档中最多3个情感子句，最多4个原因子句\n",
    "    # 一个情感子句最多的对应三个原因子句，一个原因子句唯一对应情感子句\n",
    "    with open('data/sentimental_clauses.pkl', 'rb') as f:\n",
    "        emo_dictionary = pickle.load(f)\n",
    "\n",
    "    docid_list, clause_list, pairs, \\\n",
    "    feq, feq_mask, feq_seg, feq_len, fe_clause_len, fe_doc_len, fe_adj, feq_an, fe_an_mask, \\\n",
    "    fcq, fcq_mask, fcq_seg, fcq_len, fc_clause_len, fc_doc_len, fc_adj, fcq_an, fc_an_mask, \\\n",
    "    bcq, bcq_mask, bcq_seg, bcq_len, bc_clause_len, bc_doc_len, bc_adj, bcq_an, bc_an_mask, \\\n",
    "    beq, beq_mask, beq_seg, beq_len, be_clause_len, be_doc_len, be_adj, beq_an, be_an_mask \\\n",
    "        = batch\n",
    "    # 因为是按batch=1取的，所以最外层都有维度1\n",
    "    doc_id, clause_list, true_pairs = docid_list[0], clause_list[0], pairs[0]\n",
    "    true_emo, true_cau = zip(*true_pairs)\n",
    "    true_emo, true_cau = list(true_emo), list(true_cau)\n",
    "    text = ''.join(clause_list)\n",
    "    text = ' '.join(text).split(' ')\n",
    "\n",
    "    pred_emo_f = []\n",
    "    pred_pair_f = []\n",
    "    pred_pair_f_pro = []\n",
    "    pred_pair_b = []\n",
    "    pred_pair_b_pro = []\n",
    "    pred_emo_single = []\n",
    "    pred_cau_single = []\n",
    "    aaa=[]\n",
    "    aaa_pro = []\n",
    "\n",
    "    # step 1\n",
    "    f_emo_pred = model(feq, feq_mask, feq_seg, feq_len, fe_clause_len, fe_doc_len, fe_adj, 'f_emo')\n",
    "    temp_emo_f_prob = f_emo_pred.masked_select(fe_an_mask.bool()).cpu().numpy().tolist()\n",
    "    for idx in range(len(temp_emo_f_prob)):\n",
    "        if temp_emo_f_prob[idx] > 0.99 or (temp_emo_f_prob[idx] > 0.5 and idx + 1 in emo_dictionary[str(doc_id)]):\n",
    "            pred_emo_f.append(idx)\n",
    "            pred_emo_single.append(idx + 1)\n",
    "\n",
    "    # step 2\n",
    "    for idx_emo in pred_emo_f:\n",
    "        f_query = clause_list[idx_emo]+ '这句话对应的原因子句有哪些?'\n",
    "        f_query = ' '.join(f_query).split(' ')\n",
    "        f_qa = ['[CLS]'] + f_query + ['[SEP]'] + text\n",
    "        f_qa = tokenizer.convert_tokens_to_ids([w.lower() if w not in ['[CLS]', '[SEP]'] else w for w in f_qa])\n",
    "        f_mask = [1] * len(f_qa)\n",
    "        f_seg = [0] * (len(f_query) + 2) + [1] * len(text)\n",
    "        f_len = len(f_query)\n",
    "        f_qa = torch.LongTensor([f_qa])\n",
    "        f_mask = torch.LongTensor([f_mask])\n",
    "        f_seg = torch.LongTensor([f_seg])\n",
    "        f_len = [f_len]\n",
    "        f_clause_len = fe_clause_len\n",
    "        f_doc_len = fe_doc_len\n",
    "        f_adj = fe_adj\n",
    "        f_cau_pred = model(f_qa, f_mask, f_seg, f_len, f_clause_len, f_doc_len, f_adj, 'f_cau')\n",
    "        temp_cau_f_prob = f_cau_pred[0].cpu().numpy().tolist()\n",
    "\n",
    "        # step 3\n",
    "        for idx_cau in range(len(temp_cau_f_prob)):\n",
    "            if temp_cau_f_prob[idx_cau] > 0.5 and abs(idx_emo - idx_cau) <= 11:\n",
    "                if idx_cau + 1 not in pred_cau_single:\n",
    "                    pred_cau_single.append(idx_cau + 1)\n",
    "                prob_t = temp_emo_f_prob[idx_emo] * temp_cau_f_prob[idx_cau]\n",
    "                if idx_cau - idx_emo >= 0 and idx_cau - idx_emo <= 2:\n",
    "                    pass\n",
    "                else:\n",
    "                    prob_t *= 0.9\n",
    "                pred_pair_f_pro.append(prob_t)\n",
    "                pred_pair_f.append([idx_emo + 1, idx_cau + 1])\n",
    "                aaa.append([idx_emo + 1, idx_cau + 1])\n",
    "                aaa_pro.append(prob_t)\n",
    "\n",
    "    for k in range(len(pred_pair_f)):\n",
    "        pair = pred_pair_f[k]\n",
    "        # re-think\n",
    "        idx_emo, idx_cau = pair[0] - 1, pair[1] - 1\n",
    "        b_query = clause_list[idx_cau] + '这句话对应的情感子句是哪一句?'\n",
    "        b_query = ' '.join(b_query).split(' ')\n",
    "        b_qa = ['[CLS]'] + b_query + ['[SEP]'] + text\n",
    "        b_qa = tokenizer.convert_tokens_to_ids([w.lower() if w not in ['[CLS]', '[SEP]'] else w for w in b_qa])\n",
    "        b_mask = [1] * len(b_qa)\n",
    "        b_seg = [0] * (len(b_query) + 2) + [1] * len(text)\n",
    "        b_len = len(b_query)\n",
    "        b_qa = torch.LongTensor([b_qa])\n",
    "        b_mask = torch.LongTensor([b_mask])\n",
    "        b_seg = torch.LongTensor([b_seg])\n",
    "        b_len = [b_len]\n",
    "        b_clause_len = bc_clause_len\n",
    "        b_doc_len = bc_doc_len\n",
    "        b_adj = bc_adj\n",
    "        b_emo_pred = model(b_qa, b_mask, b_seg, b_len, b_clause_len, b_doc_len, b_adj, 'b_emo')\n",
    "        temp_emo_b_prob = b_emo_pred[0].cpu().numpy().tolist()\n",
    "        for i in range(len(temp_emo_b_prob)):\n",
    "            if temp_emo_b_prob[i] > 0.5 and i + 1 in emo_dictionary[str(doc_id)]:\n",
    "                if i == idx_emo:\n",
    "                    pass\n",
    "                else:\n",
    "                    pred_pair_f_pro[k] *= 0.7\n",
    "                    pred_pair_b_pro.append(temp_emo_b_prob[i] * temp_cau_f_prob[idx_cau])\n",
    "                    pred_pair_b.append([i + 1, idx_cau + 1])\n",
    "\n",
    "                if idx_emo + 1 not in pred_emo_single:\n",
    "                    pred_emo_single.append(idx_emo + 1)\n",
    "\n",
    "\n",
    "    pred_emo_final = []\n",
    "    pred_cau_final = []\n",
    "    pred_pair_final = []\n",
    "    for i, pair in enumerate(pred_pair_b):\n",
    "        if pair not in pred_pair_f:\n",
    "            pred_pair_f.append(pair)\n",
    "            pred_pair_f_pro.append(pred_pair_b_pro[i])\n",
    "\n",
    "    for i, pair in enumerate(pred_pair_f):\n",
    "        if pred_pair_f_pro[i] > 0.5:\n",
    "            pred_pair_final.append(pair)\n",
    "\n",
    "    for pair in pred_pair_final:\n",
    "        if pair[0] not in pred_emo_final:\n",
    "            pred_emo_final.append(pair[0])\n",
    "        if pair[1] not in pred_cau_final:\n",
    "            pred_cau_final.append(pair[1])\n",
    "\n",
    "    metric_e_s, metric_c_s, _ = cal_metric(pred_emo_single, true_emo, pred_cau_single, true_cau, pred_pair_final,\n",
    "                                           true_pairs, len(clause_list))\n",
    "    metric_e, metric_c, metric_p = \\\n",
    "        cal_metric(pred_emo_final, true_emo, pred_cau_final, true_cau, pred_pair_final, true_pairs, len(clause_list))\n",
    "    return metric_e, metric_c, metric_p, metric_e_s, metric_c_s\n",
    "\n",
    "\n",
    "def evaluate(configs, test_loader, model, tokenizer):\n",
    "    model.eval()\n",
    "    all_emo, all_cau, all_pair = [0, 0, 0], [0, 0, 0], [0, 0, 0]\n",
    "    all_emo_s, all_cau_s = [0, 0, 0], [0, 0, 0]\n",
    "    for batch in test_loader:\n",
    "        emo, cau, pair, emo_s, cau_s = evaluate_one_batch(configs, batch, model, tokenizer)\n",
    "        for i in range(3):\n",
    "            all_emo[i] += emo[i]\n",
    "            all_cau[i] += cau[i]\n",
    "            all_pair[i] += pair[i]\n",
    "            all_emo_s[i] += emo_s[i]\n",
    "            all_cau_s[i] += cau_s[i]\n",
    "\n",
    "    eval_emo = eval_func(all_emo)\n",
    "    eval_cau = eval_func(all_cau)\n",
    "    eval_pair = eval_func(all_pair)\n",
    "    eval_emo_s = eval_func(all_emo_s)\n",
    "    eval_cau_s = eval_func(all_cau_s)\n",
    "    return eval_emo, eval_cau, eval_pair, eval_emo_s, eval_cau_s\n",
    "\n",
    "\n",
    "def main(configs, fold_id, tokenizer):\n",
    "    torch.manual_seed(TORCH_SEED)\n",
    "    torch.cuda.manual_seed_all(TORCH_SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "    data_path = 'data/preprocess/fold{}'.format(fold_id) + '.pt'\n",
    "    total_data = torch.load(data_path)\n",
    "    train_loader = build_dataset(configs, total_data['train'], mode='train')\n",
    "    test_loader = build_dataset(configs, total_data['test'], mode='test')\n",
    "\n",
    "    # model\n",
    "    model = Network(configs).to(DEVICE)\n",
    "    # optimizer\n",
    "    params = list(model.named_parameters())\n",
    "    optimizer_grouped_params = [\n",
    "        {'params': [p for n, p in params if '_bert' in n], 'weight_decay': 0.01},\n",
    "        {'params': [p for n, p in params if '_bert' not in n], 'lr': configs.lr, 'weight_decay': 0.01}\n",
    "    ]\n",
    "    optimizer = AdamW(params=optimizer_grouped_params, lr=configs.tuning_bert_rate)\n",
    "    # scheduler\n",
    "    training_steps = configs.epochs * len(train_loader) // configs.gradient_accumulation_steps\n",
    "    warmup_steps = int(training_steps * configs.warmup_proportion)\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer=optimizer, num_warmup_steps=warmup_steps,\n",
    "                                                num_training_steps=training_steps)\n",
    "\n",
    "    # training\n",
    "    model.zero_grad()\n",
    "    max_result_pair, max_result_emo, max_result_cau = None, None, None\n",
    "    max_result_emos, max_result_caus = None, None\n",
    "    early_stop_flag = None\n",
    "\n",
    "    for epoch in range(1, configs.epochs+1):\n",
    "        for train_step, batch in enumerate(train_loader, 1):\n",
    "            model.train()\n",
    "    \n",
    "            _, clause_list, pairs, \\\n",
    "            feq, feq_mask, feq_seg, feq_len, fe_clause_len, fe_doc_len, fe_adj, feq_an, fe_an_mask, \\\n",
    "            fcq, fcq_mask, fcq_seg, fcq_len, fc_clause_len, fc_doc_len, fc_adj, fcq_an, fc_an_mask, \\\n",
    "            bcq, bcq_mask, bcq_seg, bcq_len, bc_clause_len, bc_doc_len, bc_adj, bcq_an, bc_an_mask, \\\n",
    "            beq, beq_mask, beq_seg, beq_len, be_clause_len, be_doc_len, be_adj, beq_an, be_an_mask \\\n",
    "             = batch\n",
    "    \n",
    "            f_emo_pred = model(feq, feq_mask, feq_seg, feq_len, fe_clause_len, fe_doc_len, fe_adj, 'f_emo')\n",
    "            f_cau_pred = model(fcq, fcq_mask, fcq_seg, fcq_len, fc_clause_len, fc_doc_len, fc_adj, 'f_cau')\n",
    "            b_emo_pred = model(beq, beq_mask, beq_seg, beq_len, be_clause_len, be_doc_len, be_adj, 'b_emo')\n",
    "    \n",
    "            loss_e = model.loss_pre(f_emo_pred, feq_an, fe_an_mask)\n",
    "            loss_ec = model.loss_pre(f_cau_pred, fcq_an, fc_an_mask)\n",
    "            loss_ce = model.loss_pre(b_emo_pred, beq_an, be_an_mask)\n",
    "            losses = (loss_e + loss_ec + loss_ce) / configs.gradient_accumulation_steps\n",
    "            losses.backward()\n",
    "    \n",
    "            if train_step % configs.gradient_accumulation_steps == 0:\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                model.zero_grad()\n",
    "    \n",
    "            if train_step % 200 == 0:\n",
    "                print('epoch: {}, step: {}, loss: {}, {}, {}'.format(epoch, train_step, loss_e, loss_ec, loss_ce))\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            eval_emo, eval_cau, eval_pair, eval_emos, eval_cuas = evaluate(configs, test_loader, model, tokenizer)\n",
    "    \n",
    "            if max_result_pair is None or eval_pair[0] > max_result_pair[0]:\n",
    "                early_stop_flag = 1\n",
    "                max_result_emo = eval_emo\n",
    "                max_result_cau = eval_cau\n",
    "                max_result_pair = eval_pair\n",
    "    \n",
    "                state_dict = {'model': model.state_dict(), 'result': max_result_pair}\n",
    "                torch.save(state_dict, 'model/model_fold{}.pth'.format(fold_id))\n",
    "            else:\n",
    "                early_stop_flag += 1\n",
    "        if epoch > configs.epochs / 2 and early_stop_flag >= 7:\n",
    "            break\n",
    "\n",
    "\n",
    "    return max_result_emo, max_result_cau, max_result_pair, max_result_emos, max_result_caus\n",
    "\n",
    "total_data = torch.load('data/preprocess/fold1.pt')\n",
    "configs = Config()\n",
    "train_loader = build_dataset(configs, total_data['train'], mode='train')\n",
    "tokenizer = BertTokenizer.from_pretrained(configs.bert_cache_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_step, batch in enumerate(train_loader, 1):\n",
    "    \n",
    "    _, clause_list, pairs, \\\n",
    "    feq, feq_mask, feq_seg, feq_len, fe_clause_len, fe_doc_len, fe_adj, feq_an, fe_an_mask, \\\n",
    "    fcq, fcq_mask, fcq_seg, fcq_len, fc_clause_len, fc_doc_len, fc_adj, fcq_an, fc_an_mask, \\\n",
    "    bcq, bcq_mask, bcq_seg, bcq_len, bc_clause_len, bc_doc_len, bc_adj, bcq_an, bc_an_mask, \\\n",
    "    beq, beq_mask, beq_seg, beq_len, be_clause_len, be_doc_len, be_adj, beq_an, be_an_mask \\\n",
    "    = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['张艳和周斌结婚后',\n",
       "  '他们还在该村承包了两亩地搞养殖',\n",
       "  '这块地是张艳以周斌的名义承包的',\n",
       "  '婚后两年',\n",
       "  '周斌夫妇搬到养殖区居住',\n",
       "  '现在',\n",
       "  '婆婆又提出要继承张艳和周斌所共有的养殖区这块地',\n",
       "  '同时',\n",
       "  '张艳的两名继女也在婆婆的说教下与她反目成仇',\n",
       "  '这些接踵而至的遭遇令张艳委屈至极',\n",
       "  '婆婆认为',\n",
       "  '养殖区这块地是张艳和周斌婚后的共同财产',\n",
       "  '现在周斌去世',\n",
       "  '根据继承法的规定',\n",
       "  '法定继承遗产的第一顺序继承人为配偶子女父母',\n",
       "  '子女包括婚生子女非婚生子女',\n",
       "  '因此',\n",
       "  '她有权继承儿子的财产份额'],\n",
       " ['汪建平介绍',\n",
       "  '在八达岭野生动物世界中',\n",
       "  '和同同年龄相仿的只有胖子',\n",
       "  '它们几乎是最年轻的成年狮虎',\n",
       "  '年小体弱时',\n",
       "  '它们在各自的种群中都常受欺负',\n",
       "  '看到同同和胖子的关系改善',\n",
       "  '园里的工作人员都十分高兴',\n",
       "  '但7月20日',\n",
       "  '它们交配成功的事情',\n",
       "  '却还是出乎了大家的意料'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clause_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " '这',\n",
       " '是',\n",
       " '情',\n",
       " '感',\n",
       " '子',\n",
       " '句',\n",
       " '吗',\n",
       " '?',\n",
       " '[SEP]',\n",
       " '张',\n",
       " '艳',\n",
       " '和',\n",
       " '周',\n",
       " '斌',\n",
       " '结',\n",
       " '婚',\n",
       " '后',\n",
       " '他',\n",
       " '们',\n",
       " '还',\n",
       " '在',\n",
       " '该',\n",
       " '村',\n",
       " '承',\n",
       " '包',\n",
       " '了',\n",
       " '两',\n",
       " '亩',\n",
       " '地',\n",
       " '搞',\n",
       " '养',\n",
       " '殖',\n",
       " '这',\n",
       " '块',\n",
       " '地',\n",
       " '是',\n",
       " '张',\n",
       " '艳',\n",
       " '以',\n",
       " '周',\n",
       " '斌',\n",
       " '的',\n",
       " '名',\n",
       " '义',\n",
       " '承',\n",
       " '包',\n",
       " '的',\n",
       " '婚',\n",
       " '后',\n",
       " '两',\n",
       " '年',\n",
       " '周',\n",
       " '斌',\n",
       " '夫',\n",
       " '妇',\n",
       " '搬',\n",
       " '到',\n",
       " '养',\n",
       " '殖',\n",
       " '区',\n",
       " '居',\n",
       " '住',\n",
       " '现',\n",
       " '在',\n",
       " '婆',\n",
       " '婆',\n",
       " '又',\n",
       " '提',\n",
       " '出',\n",
       " '要',\n",
       " '继',\n",
       " '承',\n",
       " '张',\n",
       " '艳',\n",
       " '和',\n",
       " '周',\n",
       " '斌',\n",
       " '所',\n",
       " '共',\n",
       " '有',\n",
       " '的',\n",
       " '养',\n",
       " '殖',\n",
       " '区',\n",
       " '这',\n",
       " '块',\n",
       " '地',\n",
       " '同',\n",
       " '时',\n",
       " '张',\n",
       " '艳',\n",
       " '的',\n",
       " '两',\n",
       " '名',\n",
       " '继',\n",
       " '女',\n",
       " '也',\n",
       " '在',\n",
       " '婆',\n",
       " '婆',\n",
       " '的',\n",
       " '说',\n",
       " '教',\n",
       " '下',\n",
       " '与',\n",
       " '她',\n",
       " '反',\n",
       " '目',\n",
       " '成',\n",
       " '仇',\n",
       " '这',\n",
       " '些',\n",
       " '接',\n",
       " '踵',\n",
       " '而',\n",
       " '至',\n",
       " '的',\n",
       " '遭',\n",
       " '遇',\n",
       " '令',\n",
       " '张',\n",
       " '艳',\n",
       " '委',\n",
       " '屈',\n",
       " '至',\n",
       " '极',\n",
       " '婆',\n",
       " '婆',\n",
       " '认',\n",
       " '为',\n",
       " '养',\n",
       " '殖',\n",
       " '区',\n",
       " '这',\n",
       " '块',\n",
       " '地',\n",
       " '是',\n",
       " '张',\n",
       " '艳',\n",
       " '和',\n",
       " '周',\n",
       " '斌',\n",
       " '婚',\n",
       " '后',\n",
       " '的',\n",
       " '共',\n",
       " '同',\n",
       " '财',\n",
       " '产',\n",
       " '现',\n",
       " '在',\n",
       " '周',\n",
       " '斌',\n",
       " '去',\n",
       " '世',\n",
       " '根',\n",
       " '据',\n",
       " '继',\n",
       " '承',\n",
       " '法',\n",
       " '的',\n",
       " '规',\n",
       " '定',\n",
       " '法',\n",
       " '定',\n",
       " '继',\n",
       " '承',\n",
       " '遗',\n",
       " '产',\n",
       " '的',\n",
       " '第',\n",
       " '一',\n",
       " '顺',\n",
       " '序',\n",
       " '继',\n",
       " '承',\n",
       " '人',\n",
       " '为',\n",
       " '配',\n",
       " '偶',\n",
       " '子',\n",
       " '女',\n",
       " '父',\n",
       " '母',\n",
       " '子',\n",
       " '女',\n",
       " '包',\n",
       " '括',\n",
       " '婚',\n",
       " '生',\n",
       " '子',\n",
       " '女',\n",
       " '非',\n",
       " '婚',\n",
       " '生',\n",
       " '子',\n",
       " '女',\n",
       " '因',\n",
       " '此',\n",
       " '她',\n",
       " '有',\n",
       " '权',\n",
       " '继',\n",
       " '承',\n",
       " '儿',\n",
       " '子',\n",
       " '的',\n",
       " '财',\n",
       " '产',\n",
       " '份',\n",
       " '额',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(feq[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mytransformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ac96023d5347ef6c8776582d9715d38ff396f33fb25819df3c72a10bff983368"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
